{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b9ee36f",
   "metadata": {},
   "source": [
    "# 基于锚点稀疏子空间学习的非完整多视角聚类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d1fd80c",
   "metadata": {},
   "source": [
    "## 1. 前言\n",
    "\n",
    "### 1.1 符号含义\n",
    "\n",
    "- $A^{(v)} \\in R^{n_a \\times d^{(v)}}$ 为每个视角的完整子集，即在所有视角都存在的样本，其样本数为 $n_a$；\n",
    "- $U^{(v)} \\in R^{n^{(v)}_u \\times d^{(v)}}$ 为每个视角的非完整子集，即不是在所有视角都存在的样本，其样本数为 $n^{(v)}_u, v = 1,2,\\cdots,V$；\n",
    "- $n^{(v)}$ 为每个视角的存在样本数量；\n",
    "- $n_a$ 为完整子集的样本数量；\n",
    "- $n^{(v)}_u$ 为非完整子集在每个视角的样本数量；\n",
    "- $d^{(v)}$ 为和每个视角的原始特征维度；\n",
    "- $n$ 为样本总数量；\n",
    "- $V$ 为视角数量；\n",
    "- $c$ 为类簇数量；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a97f4c1",
   "metadata": {},
   "source": [
    "### 1.2 输入\n",
    "\n",
    "- $ {X}^{(v)} \\in R^{ n \\times d^{(v)} } $ 为每个视角的所有样本（不存在的样本标记为NaN）；\n",
    "- $\\bar{X}^{(v)} = [A^{(v)} ; U^{(v)}] \\in R^{ n^{(v)} \\times d^{(v)} }$ 为去掉不存在的样本并按照完整子集在前、非完整子集在后排列的数据；\n",
    "- $W^{(v)} \\in \\{0,1\\}^{n \\times n^{(v)}} $ 为缺失指示矩阵；\n",
    "- $\\lambda$ 为损失函数中的权衡参数，是超参数；\n",
    "\n",
    "$$\n",
    "W^{(v)}_{i,j} = \\begin{cases}\n",
    "1\\text{, if the $i$-th sample is the $j$-th sample presented in $v$-th view}; \\\\\n",
    "0\\text{, otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{X}^{(v)} = W^{(v)} \\bar{X}^{(v)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "n^{(v)} = \\left( n_a + n^{(v)}_u \\right) < n\\\\\n",
    "v = 1,2,\\cdots,V\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff4d0e61",
   "metadata": {},
   "source": [
    "### 1.3 输出\n",
    "\n",
    "- $ Z \\in R^{ n \\times d^{(v)} } $ 方法学到的共识完整锚点图；\n",
    "- $ C \\in \\{0,1\\}^{n \\times c} $ 是聚类结果；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffa859c1",
   "metadata": {},
   "source": [
    "## 2. 本文方法\n",
    "\n",
    "### 2.1 完整子集的视角间共识稀疏子空间矩阵的学习\n",
    "\n",
    "由于完整子集中每个样本都拥有全部的视角，因此学到的$Z_a$是视角间的共识子空间，融合了不同视角的信息。\n",
    "\n",
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\Vert Z_a^{(v)} A^{(v)} - A^{(v)} \\right\\Vert _F^2 + \\lambda \\left\\Vert Z_a^{(v)} - Z_a \\right\\Vert _F^2 \\\\\n",
    "\\text{s.t. } Z_a^{(v)} \\geq 0, Z_a^{(v)} 1 = 1, diag(Z_a^{(v)}) = 0 \\\\\n",
    "             Z_a \\geq 0, Z_a 1 = 1, diag(Z_a) = 0 \\\\\n",
    "$$\n",
    "\n",
    "- $A^{(v)}$ 为视角$v$的完整子集；\n",
    "- $Z_a^{(v)} \\in R^{n_a \\times n_a} $ 为视角$v$的完整子集上利用自表示性质构建的子空间矩阵，即完整子集的视角专属子空间矩阵；\n",
    "- $Z_a \\in R^{n_a \\times n_a}$ 为完整子集的共识子空间矩阵，即 $\\{Z_a^{(v)}\\}_{v=1}^V$ 的共同的质心；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296a52b8",
   "metadata": {},
   "source": [
    "### 2.1 非完整子集的视角内锚点子空间矩阵的学习\n",
    "\n",
    "- 非完整子集的各个视角不能完全对齐，无法学习视角间的共识子空间，\n",
    "- 但在每个视角内可以用完整子集 $A^{(v)}$ 来线性表示对应的非完整子集 $U^{(v)}$，以学到视角内锚点子空间矩阵 $Z_u^{(v)} \\in R^{{n_u}^{(v)} \\times n_a} $。\n",
    "- 然后，在每个视角 $v$ 内拼接两个子空间矩阵 $Z_a, Z_u^{(v)}$，就能得到该视角的所有存在样本到完整样本的锚点子空间矩阵 $Z^{(v)} \\in R^{{n}^{(v)} \\times n_a} $。\n",
    "\n",
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\Vert Z_u^{(v)} A^{(v)} - U^{(v)} \\right\\Vert _F^2 \\\\\n",
    "\\text{s.t. } Z_u^{(v)} \\geq 0, Z_u^{(v)} 1 = 1 \\\\\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26e8b902",
   "metadata": {},
   "source": [
    "### 2.2 各视角存在样本锚点图和完整共识锚点图的学习\n",
    "\n",
    "将上述的1. 完整子集的视角间共识稀疏子空间矩阵的学习；2. 非完整子集的视角内锚点子空间矩阵的学习；放入统一框架中进行优化。\n",
    "\n",
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\{ \\left\\Vert Z_a^{(v)} A^{(v)} - A^{(v)} \\right\\Vert _F^2 +\n",
    "\\lambda \\left\\Vert Z_a^{(v)} - Z_a \\right\\Vert _F^2 +\n",
    "\\left\\Vert Z_u^{(v)} A^{(v)} - U^{(v)} \\right\\Vert _F^2 \\right\\} \\\\\n",
    "\\text{s.t. } Z_a^{(v)} \\geq 0, Z_a^{(v)} 1 = 1, diag(Z_a^{(v)}) = 0 \\\\\n",
    "             Z_a \\geq 0, Z_a 1 = 1, diag(Z_a) = 0 \\\\\n",
    "             Z_u^{(v)} \\geq 0, Z_u^{(v)} 1 = 1\n",
    "$$\n",
    "\n",
    "- 各视角存在样本锚点图计算如下： $Z^{(v)} = [ Z_a ; Z_u^{(v)} ] \\in R^{n^{(v)} \\times n_a} $ ；\n",
    "- 完整共识锚点图计算如下： $Z = \\frac{1}{V} \\sum_{v=1}^V W^{(v)} Z^{(v)}$ ；\n",
    "- 对共识锚点图 $Z$ 进行快速谱聚类（Fast Spectral Clustering）即可获得最终聚类结果$C$ ；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2537890",
   "metadata": {},
   "source": [
    "### 2.3 等价的无约束损失函数及其优化\n",
    "\n",
    "为了便于使用PyTorch的基于自动微分的优化算法，加快优化效率，将上述目标函数等价改写为一个等价的无约束损失函数。\n",
    "\n",
    "- 用掩码softmax激活函数$\\sigma_M(X)$实现约束条件 $Z \\geq 0, Z 1 = 1, diag(Z)=0$，即：\n",
    "  - $Z$的元素大于等于0；\n",
    "  - $Z$的每行元素之和都为1；\n",
    "  - $Z$的对角线元素为0；\n",
    "- 使用均方误差损失 $\\mathcal{L}_{MSE}(X, Y)$ 来实现F范数误差，即$\\left\\Vert X - Y \\right\\Vert_F^2$；\n",
    "- 待求的子空间矩阵 $\\{Z_a,Z_a^{(v)},Z_u^{(v)}\\}_{v=1}^V$ 分别用可学习参数 $\\{\\Theta_a,\\Theta_a^{(v)},\\Theta_u^{(v)}\\}_{v=1}^V$ 表示；\n",
    "- 使用Adam优化算法最小化损失函数 $\\mathcal{L}_{\\text{ABSS-IMC}}$ 即可；\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{ABS2-IMC}} = \n",
    "\\sum_{v=1}^V \\left\\{ \\mathcal{L}_{MSE} \\left( \\sigma_M(\\Theta_a^{(v)}) A^{(v)}, A^{(v)} \\right) +\n",
    "\\lambda \\mathcal{L}_{MSE} \\left( \\Theta_a^{(v)} , \\Theta_a \\right) +\n",
    "\\mathcal{L}_{MSE} \\left( \\sigma(\\Theta_u^{(v)}) , U^{(v)} \\right)\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "掩码softmax激活函数定义如下：\n",
    "$$\n",
    "[\\sigma_M(X)]_{i,j} = \\frac{\\exp(X_{i,j}) \\cdot M_{i,j}}{\\sum_{j=1}^n \\exp(X_{i,j}) \\cdot M_{i,j}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dae63db7",
   "metadata": {},
   "source": [
    "## 3. 实现细节\n",
    "\n",
    "### 3.1 前处理步骤\n",
    "\n",
    "- 归一化：将每个特征归一化为0-1之间的实数；\n",
    "\n",
    "$$\n",
    "\\tilde{X} = \\frac{X - \\min_i \\{X_i\\}}{\\max_i \\{X_i\\}}\n",
    "$$\n",
    "\n",
    "- 将归一化后的数据重新组织为$\\bar{X}^{(v)} = [A^{(v)} ; U^{(v)}]$，其中；\n",
    "  - $A^{(v)} \\in R^{n_a \\times d^{(v)}}$ 为每个视角的完整子集，即在所有视角都存在的样本，其样本数为 $n_a$；\n",
    "  - $U^{(v)} \\in R^{n^{(v)}_u \\times d^{(v)}}$ 为每个视角的非完整子集，即不是在所有视角都存在的样本，其样本数为 $n^{(v)}_u, v = 1,2,\\cdots,V$；\n",
    "  - 重新组织后的数据$\\bar{X}^{(v)}$ 与原始数据${X}^{(v)}$ 之间的关系为：${X}^{(v)} = W^{(v)} \\bar{X}^{(v)}$；\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07f58a05",
   "metadata": {},
   "source": [
    "### 3.2 后处理步骤\n",
    "\n",
    "- 从可学习参数 $\\{\\Theta_a,\\Theta_u^{(v)}\\}_{v=1}^V$ 得到 $\\{Z_a,Z_u^{(v)}\\}_{v=1}^V$ 如下：\n",
    "  - $Z_a = \\sigma_M(X)$；\n",
    "  - $Z_u^{(v)} = \\sigma(\\Theta_u^{(v)})$；\n",
    "- 从$Z_a,\\{Z_u^{(v)}\\}_{v=1}^V$ 得到完整共识锚点图$Z$ 如下：\n",
    "  - $Z^{(v)} = [ Z_a ; Z_u^{(v)} ] \\in R^{n^{(v)} \\times n_a} $ ；\n",
    "  - $Z = \\frac{1}{V} \\sum_{v=1}^V W^{(v)} Z^{(v)}$ ；\n",
    "- 对完整共识锚点图$Z$进行快速谱聚类如下：\n",
    "  - 对$Z$进行奇异值分解，即 $Z=P\\Sigma Q^T$；\n",
    "  - $Z$ 的左奇异向量$P \\in R^{n \\times c}$即为$Z$的谱嵌入，取原始的左奇异向量$P$的前$c$个特征；\n",
    "  - 对$P$的模长进行归一化，即$\\tilde{P}_i = \\frac{P_i}{||P_i||_F}$；\n",
    "  - 对归一化后的$\\tilde{P}_i$进行K-means聚类，得到最终聚类结果$C \\in \\{0, 1\\}^{n \\times c}$；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8781d9",
   "metadata": {},
   "source": [
    "### 3.3 超参数设置\n",
    "\n",
    "- 使用 Adam 优化器，学习率设置为0.001；\n",
    "- 超参数 $\\lambda$ 设置为0.1；"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
