{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b9ee36f",
   "metadata": {},
   "source": [
    "# Anchor-based Sparse Subspace Incomplete Multi-view Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab84fdf",
   "metadata": {},
   "source": [
    "\n",
    "![image.png](image.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d1fd80c",
   "metadata": {},
   "source": [
    "### Symbol description\n",
    "\n",
    "- $A^{(v)} \\in R^{n_a \\times d^{(v)}}$ is the view-complete subset for each view. Each sample  has all the views. Its size is $n_a$.\n",
    "- $U^{(v)} \\in R^{n^{(v)}_u \\times d^{(v)}}$ is the incomplete subset for each view. Each sample only has parts of the views. Its size is $n^{(v)}_u, v = 1,2,\\cdots,V$.\n",
    "- $n^{(v)}$ is the number of existent samples of each view.\n",
    "- $n_a$ is the number of samples of the complete subset.\n",
    "- $n^{(v)}_u$ is the number of samples of the incomplete subset of each view.\n",
    "- $d^{(v)}$ is the original feature dimension of each view.\n",
    "- $n$ is the total number of samples.\n",
    "- $V$ is the number of views.\n",
    "- $c$ is the number of clusters, which is given by the user."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a97f4c1",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "- $ {X}^{(v)} \\in R^{ n \\times d^{(v)} } $ are all the samples of each view, where inexistent samples are marked with NaN.\n",
    "- $\\bar{X}^{(v)} = [A^{(v)} ; U^{(v)}] \\in R^{ n^{(v)} \\times d^{(v)} }$ are the reorganized samples of each view, where inexistent samples are dropped and the complete subset is arranged before the incomplete subset.\n",
    "- $W^{(v)} \\in \\{0,1\\}^{n \\times n^{(v)}} $ is the missing indicator matrix.\n",
    "- $\\lambda$ is the balancing parameter in the loss function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07b217d5",
   "metadata": {},
   "source": [
    "$$\n",
    "W^{(v)}_{i,j} = \\begin{cases}\n",
    "1\\text{, if the $i$-th sample is the $j$-th sample presented in $v$-th view}; \\\\\n",
    "0\\text{, otherwise}.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2d2a7e9",
   "metadata": {},
   "source": [
    "$$\n",
    "{X}^{(v)} = W^{(v)} \\bar{X}^{(v)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49982b86",
   "metadata": {},
   "source": [
    "$$\n",
    "n^{(v)} = \\left( n_a + n^{(v)}_u \\right) < n\\\\\n",
    "v = 1,2,\\cdots,V\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff4d0e61",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "\n",
    "- $ Z \\in R^{ n \\times d^{(v)} } $ is the complete consensus anchor graph learned by our method.\n",
    "- $ C \\in \\{0,1\\}^{n \\times c} $ are the clustering results；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffa859c1",
   "metadata": {},
   "source": [
    "## Learning an inter-view consensus sparse subspace matrix for the complete subset\n",
    "\n",
    "Since each sample of the complete subset possesses all the view, the learned $Z_a$ is the consensus subspace cross the views, which fuses information from different views."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f55f7281",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\Vert Z_a^{(v)} A^{(v)} - A^{(v)} \\right\\Vert _F^2 + \\lambda \\left\\Vert Z_a^{(v)} - Z_a \\right\\Vert _F^2 \\\\\n",
    "\\text{s.t. } Z_a^{(v)} \\geq 0, Z_a^{(v)} 1 = 1, diag(Z_a^{(v)}) = 0 \\\\\n",
    "             Z_a \\geq 0, Z_a 1 = 1, diag(Z_a) = 0 \\\\\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7b32501",
   "metadata": {},
   "source": [
    "- $A^{(v)}$ is the complete subset of view $v$.\n",
    "- $Z_a^{(v)} \\in R^{n_a \\times n_a} $ is the subspace matrix of the complete subset of view $v$ constructed by self-representative property.\n",
    "- $Z_a \\in R^{n_a \\times n_a}$ is the consensus subspace matrix of the complete subset, that is, the centroid of $\\{Z_a^{(v)}\\}_{v=1}^V$ ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296a52b8",
   "metadata": {},
   "source": [
    "## Learning the intra-view anchor-based subspace matrices for the incomplete subset\n",
    "\n",
    "- Since the samples of the incomplete subset are not perfectly aligned, no inter-view consensus subspace can be learned.\n",
    "- Yet within each view, we can linearly combine samples of $A^{(v)}$ to approximate $U^{(v)}$ so as to learn their relationships as $Z_u^{(v)} \\in R^{{n_u}^{(v)} \\times n_a} $.\n",
    "- Then, concatenate two subspace matrices $Z_a, Z_u^{(v)}$ within each view to obtain the anchor graph (bipartile graph) of that view $Z^{(v)} \\in R^{{n}^{(v)} \\times n_a} $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b8c6d83",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\Vert Z_u^{(v)} A^{(v)} - U^{(v)} \\right\\Vert _F^2 \\\\\n",
    "\\text{s.t. } Z_u^{(v)} \\geq 0, Z_u^{(v)} 1 = 1 \\\\\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26e8b902",
   "metadata": {},
   "source": [
    "## Leanring a anchor graph for view existent samples and a complete consensus anchor graph\n",
    "\n",
    "Putting the above 1. inter-view consensus sparse subspace learning and 2. intra-view anchor-based sparse subspace learning into a unified optimization problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e20b384",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\{ \\left\\Vert Z_a^{(v)} A^{(v)} - A^{(v)} \\right\\Vert _F^2 +\n",
    "\\lambda \\left\\Vert Z_a^{(v)} - Z_a \\right\\Vert _F^2 +\n",
    "\\left\\Vert Z_u^{(v)} A^{(v)} - U^{(v)} \\right\\Vert _F^2 \\right\\} \\\\\n",
    "\\text{s.t. } Z_a^{(v)} \\geq 0, Z_a^{(v)} 1 = 1, diag(Z_a^{(v)}) = 0 \\\\\n",
    "             Z_a \\geq 0, Z_a 1 = 1, diag(Z_a) = 0 \\\\\n",
    "             Z_u^{(v)} \\geq 0, Z_u^{(v)} 1 = 1\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "318df075",
   "metadata": {},
   "source": [
    "- Compute the anchor graph of the existent samples of each view as: $Z^{(v)} = [ Z_a ; Z_u^{(v)} ] \\in R^{n^{(v)} \\times n_a} $.\n",
    "- Compute the complete consensus anchor graph as: $Z = \\frac{1}{V} \\sum_{v=1}^V W^{(v)} Z^{(v)}$ .\n",
    "- Perform Fast Spectral Clustering on $Z$ and obtain the final clustering results $C$ ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2537890",
   "metadata": {},
   "source": [
    "## Equivalent unconstrained loss and its optimization\n",
    "\n",
    "We transform the above objective function into an equivalent unconstrained form to take advantage of autograd and hardware acceleration of PyTorch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b8f92cc",
   "metadata": {},
   "source": [
    "- 用掩码softmax激活函数$\\sigma_m(X, M)$实现约束条件 $Z \\geq 0, Z 1 = 1, diag(Z)=0$，即：\n",
    "  - $Z$的元素大于等于0；\n",
    "  - $Z$的每行元素之和都为1；\n",
    "  - $Z$的对角线元素为0；\n",
    "- 使用均方误差损失 $\\mathcal{L}_{MSE}(X, Y)$ 来实现F范数误差，即$\\left\\Vert X - Y \\right\\Vert_F^2$；\n",
    "- 待求的子空间矩阵 $\\{Z_a,Z_a^{(v)},Z_u^{(v)}\\}_{v=1}^V$ 分别用可学习参数 $\\{\\Theta_a,\\Theta_a^{(v)},\\Theta_u^{(v)}\\}_{v=1}^V$ 表示；\n",
    "- 使用Adam优化算法最小化损失函数 $\\mathcal{L}_{\\text{ABSS-IMC}}$ 即可；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa91558a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{\\text{ABSS-IMC}} = \n",
    "\\sum_{v=1}^V \\left\\{ \\mathcal{L}_{MSE} \\left( \\sigma_m(\\Theta_a^{(v)}, M_{n_a}) A^{(v)}, A^{(v)} \\right) +\n",
    "\\lambda \\mathcal{L}_{MSE} \\left( \\Theta_a^{(v)} , \\Theta_a \\right) +\n",
    "\\mathcal{L}_{MSE} \\left( \\sigma(\\Theta_u^{(v)}) , U^{(v)} \\right)\n",
    "\\right\\}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15f0bed1",
   "metadata": {},
   "source": [
    "$$\n",
    "[\\sigma_m(X, M)]_{i,j} = \\frac{\\exp(X_{i,j}) \\cdot M_{i,j}}{\\sum_{j=1}^n \\exp(X_{i,j}) \\cdot M_{i,j}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dae63db7",
   "metadata": {},
   "source": [
    "## 前后处理\n",
    "\n",
    "- 前处理：在优化损失函数之前，对输入进行前处理；\n",
    "- 后处理：在优化损失函数之后，学到了参数$\\{\\Theta_a,\\Theta_a^{(v)},\\Theta_u^{(v)}\\}_{v=1}^V$，再进行后处理以获得聚类结果$C$和完整共识锚点图$Z$；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "575079ee",
   "metadata": {},
   "source": [
    "### Preprocessing steps\n",
    "\n",
    "- Normalize each feature to a real number in [0, 1];\n",
    "- Reorganize the normalized features into the form of $\\bar{X}^{(v)} = [A^{(v)} ; U^{(v)}]$, where:\n",
    "  - $A^{(v)} \\in R^{n_a \\times d^{(v)}}$ is the complete subset for each view.\n",
    "  - $U^{(v)} \\in R^{n^{(v)}_u \\times d^{(v)}}$ is the incomplete subset for each view.\n",
    "- The relationship between $\\bar{X}^{(v)}$ and ${X}^{(v)}$ is: ${X}^{(v)} = W^{(v)} \\bar{X}^{(v)}$；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f7ec223",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{X} = \\frac{X - \\min_i \\{X_i\\}}{\\max_i \\{X_i\\}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07f58a05",
   "metadata": {},
   "source": [
    "### Postprocessing steps\n",
    "\n",
    "- 从可学习参数 $\\{\\Theta_a,\\Theta_u^{(v)}\\}_{v=1}^V$ 得到 $\\{Z_a,Z_u^{(v)}\\}_{v=1}^V$ 如下：\n",
    "  - $Z_a = \\sigma(M \\Theta_a)$；\n",
    "  - $Z_u^{(v)} = \\sigma(\\Theta_u^{(v)})$；\n",
    "- 从$Z_a,\\{Z_u^{(v)}\\}_{v=1}^V$ 得到完整共识锚点图$Z$ 如下：\n",
    "  - $Z^{(v)} = [ Z_a ; Z_u^{(v)} ] \\in R^{n^{(v)} \\times n_a} $ ；\n",
    "  - $Z = \\frac{1}{V} \\sum_{v=1}^V W^{(v)} Z^{(v)}$ ；\n",
    "- 对完整共识锚点图$Z$进行快速谱聚类如下：\n",
    "  - 对$Z$进行奇异值分解，即 $Z=P\\Sigma Q^T$；\n",
    "  - $Z$ 的左奇异向量$P \\in R^{n \\times c}$即为$Z$的谱嵌入，取原始的左奇异向量$P$的前$c$个特征；\n",
    "  - 对$P$的模长进行归一化，即$\\tilde{P}_i = \\frac{P_i}{||P_i||_F}$；\n",
    "  - 对归一化后的$\\tilde{P}_i$进行K-means聚类，得到最终聚类结果$C \\in \\{0, 1\\}^{n \\times c}$；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8781d9",
   "metadata": {},
   "source": [
    "## 实现细节\n",
    "\n",
    "- Use Adam optimizer with learning rate set to 0.1.\n",
    "- Hyper-parameter $\\lambda$ is set to 0.1.\n",
    "- Take the first $c$ features of the left singular matrix $P$ and perform $L_2$ normalization on it when doing spectral clustering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a87932926120c6dca57d15863bd780c43ae6921282476fa1d363c46120a8446c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
