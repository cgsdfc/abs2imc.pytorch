{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b9ee36f",
   "metadata": {},
   "source": [
    "# Anchor-based Sparse Subspace Incomplete Multi-view Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d1fd80c",
   "metadata": {},
   "source": [
    "## 1. Preliminaries\n",
    "\n",
    "### 1.1 Symbols\n",
    "\n",
    "- $A^{(v)} \\in R^{n_a \\times d^{(v)}}$ is the view-complete subset for each view. Each sample  has all the views. Its size is $n_a$.\n",
    "- $U^{(v)} \\in R^{n^{(v)}_u \\times d^{(v)}}$ is the incomplete subset for each view. Each sample only has parts of the views. Its size is $n^{(v)}_u, v = 1,2,\\cdots,V$.\n",
    "- $n^{(v)}$ is the number of existent samples of each view.\n",
    "- $n_a$ is the number of samples of the complete subset.\n",
    "- $n^{(v)}_u$ is the number of samples of the incomplete subset of each view.\n",
    "- $d^{(v)}$ is the original feature dimension of each view.\n",
    "- $n$ is the total number of samples.\n",
    "- $V$ is the number of views.\n",
    "- $c$ is the number of clusters, which is given by the user."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a97f4c1",
   "metadata": {},
   "source": [
    "### 1.2 Inputs\n",
    "\n",
    "- $ {X}^{(v)} \\in R^{ n \\times d^{(v)} } $ are all the samples of each view, where inexistent samples are marked with NaN.\n",
    "- $\\bar{X}^{(v)} = [A^{(v)} ; U^{(v)}] \\in R^{ n^{(v)} \\times d^{(v)} }$ are the reorganized samples of each view, where inexistent samples are dropped and the complete subset is arranged before the incomplete subset.\n",
    "- $W^{(v)} \\in \\{0,1\\}^{n \\times n^{(v)}} $ is the missing indicator matrix.\n",
    "- $\\lambda$ is the balancing parameter in the loss function.\n",
    "\n",
    "$$\n",
    "W^{(v)}_{i,j} = \\begin{cases}\n",
    "1\\text{, if the $i$-th sample is the $j$-th sample presented in $v$-th view}; \\\\\n",
    "0\\text{, otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{X}^{(v)} = W^{(v)} \\bar{X}^{(v)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "n^{(v)} = \\left( n_a + n^{(v)}_u \\right) < n\\\\\n",
    "v = 1,2,\\cdots,V\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff4d0e61",
   "metadata": {},
   "source": [
    "### 1.3 Outputs\n",
    "\n",
    "- $ Z \\in R^{ n \\times d^{(v)} } $ is the complete consensus anchor graph learned by our method.\n",
    "- $ C \\in \\{0,1\\}^{n \\times c} $ are the clustering results；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffa859c1",
   "metadata": {},
   "source": [
    "## 2. Our method\n",
    "\n",
    "### 2.1 Learning an inter-view consensus sparse subspace matrix for the complete subset\n",
    "\n",
    "Since each sample of the complete subset possesses all the view, the learned $Z_a$ is the consensus subspace cross the views, which fuses information from different views.\n",
    "\n",
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\Vert Z_a^{(v)} A^{(v)} - A^{(v)} \\right\\Vert _F^2 + \\lambda \\left\\Vert Z_a^{(v)} - Z_a \\right\\Vert _F^2 \\\\\n",
    "\\text{s.t. } Z_a^{(v)} \\geq 0, Z_a^{(v)} 1 = 1, diag(Z_a^{(v)}) = 0 \\\\\n",
    "             Z_a \\geq 0, Z_a 1 = 1, diag(Z_a) = 0 \\\\\n",
    "$$\n",
    "\n",
    "- $A^{(v)}$ is the complete subset of view $v$.\n",
    "- $Z_a^{(v)} \\in R^{n_a \\times n_a} $ is the subspace matrix of the complete subset of view $v$ constructed by self-representative property.\n",
    "- $Z_a \\in R^{n_a \\times n_a}$ is the consensus subspace matrix of the complete subset, that is, the centroid of $\\{Z_a^{(v)}\\}_{v=1}^V$ ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296a52b8",
   "metadata": {},
   "source": [
    "### 2.2 Learning the intra-view anchor-based subspace matrices for the incomplete subset\n",
    "\n",
    "- Since the samples of the incomplete subset are not perfectly aligned, no inter-view consensus subspace can be learned.\n",
    "- Yet within each view, we can linearly combine samples of $A^{(v)}$ to approximate $U^{(v)}$ so as to learn their relationships as $Z_u^{(v)} \\in R^{{n_u}^{(v)} \\times n_a} $.\n",
    "- Then, concatenate two subspace matrices $Z_a, Z_u^{(v)}$ within each view to obtain the anchor graph (bipartile graph) of that view $Z^{(v)} \\in R^{{n}^{(v)} \\times n_a} $.\n",
    "\n",
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\Vert Z_u^{(v)} A^{(v)} - U^{(v)} \\right\\Vert _F^2 \\\\\n",
    "\\text{s.t. } Z_u^{(v)} \\geq 0, Z_u^{(v)} 1 = 1 \\\\\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26e8b902",
   "metadata": {},
   "source": [
    "### 2.3 Leanring a anchor graph for view existent samples and a complete consensus anchor graph\n",
    "\n",
    "Putting the above 1. inter-view consensus sparse subspace learning and 2. intra-view anchor-based sparse subspace learning into a unified optimization problem.\n",
    "\n",
    "\n",
    "- Compute the anchor graph of the existent samples of each view as: $Z^{(v)} = [ Z_a ; Z_u^{(v)} ] \\in R^{n^{(v)} \\times n_a} $.\n",
    "- Compute the complete consensus anchor graph as: $Z = \\frac{1}{V} \\sum_{v=1}^V W^{(v)} Z^{(v)}$ .\n",
    "- Perform Fast Spectral Clustering on $Z$ and obtain the final clustering results $C$ .\n",
    "\n",
    "\n",
    "$$\n",
    "\\min \\sum_{v=1}^V \\left\\{ \\left\\Vert Z_a^{(v)} A^{(v)} - A^{(v)} \\right\\Vert _F^2 +\n",
    "\\lambda \\left\\Vert Z_a^{(v)} - Z_a \\right\\Vert _F^2 +\n",
    "\\left\\Vert Z_u^{(v)} A^{(v)} - U^{(v)} \\right\\Vert _F^2 \\right\\} \\\\\n",
    "\\text{s.t. } Z_a^{(v)} \\geq 0, Z_a^{(v)} 1 = 1, diag(Z_a^{(v)}) = 0 \\\\\n",
    "             Z_a \\geq 0, Z_a 1 = 1, diag(Z_a) = 0 \\\\\n",
    "             Z_u^{(v)} \\geq 0, Z_u^{(v)} 1 = 1\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2537890",
   "metadata": {},
   "source": [
    "### 2.4 Equivalent unconstrained loss and its optimization\n",
    "\n",
    "We transform the above objective function into an equivalent unconstrained form to take advantage of autograd and hardware acceleration of PyTorch. \n",
    "\n",
    "- Use masked softmax activation function $\\sigma_M(X)$ to substitute constrains $Z \\geq 0, Z 1 = 1, diag(Z)=0$.\n",
    "- Use mean squared error $\\mathcal{L}_{MSE}(X, Y)$ to implement F-norm error, i.e., $\\left\\Vert X - Y \\right\\Vert_F^2$.\n",
    "- The expectant subspace matrices $\\{Z_a,Z_a^{(v)},Z_u^{(v)}\\}_{v=1}^V$ are solved by the learnable variables $\\{\\Theta_a,\\Theta_a^{(v)},\\Theta_u^{(v)}\\}_{v=1}^V$, respectively.\n",
    "- Usee Adam to minimize the loss $\\mathcal{L}_{\\text{ABS2-IMC}}$.\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{ABS2-IMC}} = \n",
    "\\sum_{v=1}^V \\left\\{ \\mathcal{L}_{MSE} \\left( \\sigma_M(\\Theta_a^{(v)}) A^{(v)}, A^{(v)} \\right) +\n",
    "\\lambda \\mathcal{L}_{MSE} \\left( \\Theta_a^{(v)} , \\Theta_a \\right) +\n",
    "\\mathcal{L}_{MSE} \\left( \\sigma(\\Theta_u^{(v)}) , U^{(v)} \\right)\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "The definition of the masked softmax activation function is as follows:\n",
    "$$\n",
    "[\\sigma_M(X)]_{i,j} = \\frac{\\exp(X_{i,j}) \\cdot M_{i,j}}{\\sum_{j=1}^n \\exp(X_{i,j}) \\cdot M_{i,j}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dae63db7",
   "metadata": {},
   "source": [
    "## 3. Implementation details\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "575079ee",
   "metadata": {},
   "source": [
    "### 3.1 Preprocessing steps\n",
    "\n",
    "1. Normalize each feature to a real number in [0, 1];\n",
    "\n",
    "$$\n",
    "\\tilde{X} = \\frac{X - \\min_i \\{X_i\\}}{\\max_i \\{X_i\\}}\n",
    "$$\n",
    "\n",
    "2. Reorganize the normalized features into the form of $\\bar{X}^{(v)} = [A^{(v)} ; U^{(v)}]$, where:\n",
    "   - $A^{(v)} \\in R^{n_a \\times d^{(v)}}$ is the complete subset for each view.\n",
    "   - $U^{(v)} \\in R^{n^{(v)}_u \\times d^{(v)}}$ is the incomplete subset for each view.\n",
    "   - The relationship between $\\bar{X}^{(v)}$ and ${X}^{(v)}$ is: ${X}^{(v)} = W^{(v)} \\bar{X}^{(v)}$；\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07f58a05",
   "metadata": {},
   "source": [
    "### 3.2 Postprocessing steps\n",
    "\n",
    "1. Obtain $\\{Z_a,Z_u^{(v)}\\}_{v=1}^V$ from learnable parameters $\\{\\Theta_a,\\Theta_u^{(v)}\\}_{v=1}^V$ as follows:\n",
    "   - $Z_a = \\sigma_m(\\Theta_a, M)$ .\n",
    "   - $Z_u^{(v)} = \\sigma(\\Theta_u^{(v)})$ .\n",
    "\n",
    "\n",
    "2. Obtain $Z$ from $Z_a,\\{Z_u^{(v)}\\}_{v=1}^V$ as follows:\n",
    "   - $Z^{(v)} = [ Z_a ; Z_u^{(v)} ] \\in R^{n^{(v)} \\times n_a} $.\n",
    "   - $Z = \\frac{1}{V} \\sum_{v=1}^V W^{(v)} Z^{(v)}$ .\n",
    "\n",
    "\n",
    "3. Perform clustering on $Z$ as follows:\n",
    "   - Perform singluar decomposition on $Z$, i.e., $Z=P\\Sigma Q^T$.\n",
    "   - The left singular matrix of $Z$ (i.e., $P \\in R^{n \\times c}$) is the spectral embeddings of $Z$.\n",
    "   - Take the first $c$ features of $P$ as we have $c$ clusters.\n",
    "   - Perform normalization on $P$, i.e., $\\tilde{P}_i = \\frac{P_i}{||P_i||_F}$.\n",
    "   - Perform K-means on the normaliezd $\\tilde{P}_i$ to get $C \\in \\{0, 1\\}^{n \\times c}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8781d9",
   "metadata": {},
   "source": [
    "### 3.3 Hyper-parameters settings\n",
    "\n",
    "- Use Adam optimizer with learning rate set to 0.1.\n",
    "- Hyper-parameter $\\lambda$ is set to 0.1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
