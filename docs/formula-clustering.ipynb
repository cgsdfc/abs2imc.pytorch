{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b9ee36f",
   "metadata": {},
   "source": [
    "# 基于图卷积神经网络t-SNE共识表示学习的非完整多视角特征补全的\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab84fdf",
   "metadata": {},
   "source": [
    "## 网络结构\n",
    "\n",
    "![image.png](image-small.png)\n",
    "\n",
    "网络结构图"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a97f4c1",
   "metadata": {},
   "source": [
    "### 网络输入 Network Inputs\n",
    "\n",
    "- $ \\tilde{X}^{(v)} \\in R^{ n^{(v)} \\times d^{(v)} } $ 为每个视角的存在样本；\n",
    "- $ {X}^{(v)} \\in R^{ n \\times d^{(v)} } $ 为每个视角的所有样本（不存在的样本标记为NaN）；\n",
    "- $M^{(v)} \\in \\{0,1\\}^{n^{(v)} \\times n} $ 为缺失指示矩阵；\n",
    "- $  n^{(v)}, d^{(v)} $ 分别为每个视角的存在样本数量和每个视角的原始特征维度；\n",
    "- $ n, V $ 分别为样本数量（总数量，包括缺失和非缺失的）和视角数量；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fb3e025",
   "metadata": {},
   "source": [
    "$$\n",
    " M^{(v)}_{i,j} = \\begin{cases}\n",
    "    1,\\text{ if sample $j$ is the $i$-th sample that exists,} \\\\\n",
    "    0,\\text{ otherwise}\n",
    " \\end{cases}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb87abf7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{X}^{(v)} = M^{(v)} {X}^{(v)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff4d0e61",
   "metadata": {},
   "source": [
    "### 网络输出 Network Outputs\n",
    "\n",
    "- $ \\hat{X}^{(v)} \\in R^{ n^{(v)} \\times d^{(v)} } $ 是网络为每个视角重建的原始特征，其中包含对存在样本的重建和对不存在样本（缺失样本）的预测（补全）；\n",
    "- $H \\in R^{n \\times d} $ 是网络学习到的共识表示，可用于聚类等其他下游任务，$d$ 是共识表示的维度；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffa859c1",
   "metadata": {},
   "source": [
    "## 共识表示学习模块 Consensus Representation Learning Module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71fb296c",
   "metadata": {},
   "source": [
    "### 构图 Graph Construction\n",
    "\n",
    "- 从 $\\tilde{X}^{(v)}$ 中构建 $\\tilde{P}^{(v)}, \\tilde{A}^{(v)} \\in R^{ n^{(v)} \\times n^{(v)} } $；\n",
    "- $\\tilde{P}^{(v)}$ 是视角v的存在样本的原始数据分布，是高斯分布，用作t-SNE损失函数的监督信号；\n",
    "- $\\tilde{A}^{(v)}$ 是视角v的存在样本的归一化的相似度图，用作GCN的图输入；\n",
    "- $\\tilde{S}^{(v)}$ 是视角v的存在样本的未归一化相似度图（基于高斯核，也可以基于其他核函数）；\n",
    "- $\\tilde{D}^{(v)} \\in R^{ n^{(v)} \\times n^{(v)} } $ 是对角矩阵，用于对 $\\tilde{A}^{(v)}$ 进行归一化；\n",
    "- $I_{n^{(v)}} \\in R^{ n^{(v)} \\times n^{(v)} }$ 是单位矩阵，用于使得图包含自环；\n",
    "- $\\sigma_i$ 是根据困惑度PPL（模型的超参数）利用二分查找求出；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909166b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{S}_{i,j} = \\frac{ \\exp\\left(-||\\tilde{x}_i - \\tilde{x}_j||^2 / 2 \\sigma_i^2\n",
    "\\right)}{\\sum_{k\\neq i}\\exp\\left(-||\\tilde{x}_i - \\tilde{x}_k||^2 / 2 \\sigma_i^2\\right)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc8ff53b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{P}^{(v)} = \\frac{1}{2} \\left(\\tilde{S}^{(v)} + (\\tilde{S}^{(v)})^T\\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f46772c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{A}^{(v)} = (\\tilde{D}^{(v)})^{-1/2} \\left( \\tilde{S}^{(v)} + I_{n^{(v)}} \\right) (\\tilde{D}^{(v)})^{-1/2}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8241d29f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{D}_{i,i}^{(v)} = \\sum_{j=1}^{n^{(v)}} \\tilde{S}_{i,j}^{(v)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f347b582",
   "metadata": {},
   "source": [
    "### 困惑度超参数\n",
    "\n",
    "- 困惑度Perplexity（PPL），决定了原始特征的每个样本周围有多少邻居；\n",
    "- $H(P)$ 表示分布$P$的熵；\n",
    "- $P_i$ 表示$i$出现的概率；\n",
    "- 根据设定的PPL，用二分搜索得到对应的$\\sigma$；\n",
    "  - 每给定一个$\\sigma$，就得到一个分布$P$；\n",
    "  - 由此计算到$H(P)$和PPL；\n",
    "  - 判断两个PPL是否相等，不等则继续搜索；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de5b1b82",
   "metadata": {},
   "source": [
    "$$\n",
    "PPL(P) = 2^{H(P)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f932835",
   "metadata": {},
   "source": [
    "$$\n",
    "H(P) = -\\sum_{i} P_{i} \\log_2 P_{i}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc2f1f8f",
   "metadata": {},
   "source": [
    "### 视角专属编码器 View-specific Encoder\n",
    "\n",
    "- $ \\tilde{H}^{(v)} \\in R^{n^{(v)} \\times {d^{(v)}}} $ 是编码器输出的特征\n",
    "- $ f^{(v)} $ 是编码器，$ \\Theta_E^{(v)} $ 是编码器的可学习参数；\n",
    "- $ H \\in R^{n \\times d} $ 是共识表示，$d$ 是共识表示的维度；\n",
    "- $ \\bar{H}^{(v)} $ 是共识表示到各视角的投影；\n",
    "- 编码器由图卷积层和批归一化层组成；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95f7f635",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{H}^{(v)} = f^{(v)}\\left(\\tilde{X}^{(v)}, \\tilde{A}^{(v)}; \\Theta_E^{(v)}\\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7e5ca20",
   "metadata": {},
   "source": [
    "$$\n",
    "H = \\sum_{v=1}^V (M^{(v)})^T \\tilde{H}^{(v)} \\\\\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3d269ee",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{H}^{(v)} = M^{(v)} H\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fec256fb",
   "metadata": {},
   "source": [
    "### 图卷积层 Graph Convolutional Layer\n",
    "\n",
    "- $ReLU(x) = \\max(0, x)$ ；\n",
    "- $H^{(l)}$ 是网络第$l$层的输入，$H^{(0)} = X$ 是网络的输入；\n",
    "- $H^{(l+1)}$ 是网络第$l$层的输出，也是第$l+1$层的输入；\n",
    "- $\\tilde{A}$ 是归一化的相似度图，用作GCN的图输入；\n",
    "- $W^{(l)}$ 是网络第$l$层的可学习参数；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32b56757",
   "metadata": {},
   "source": [
    "$$\n",
    "H^{(l+1)} = ReLU \\left( \\tilde{A} H^{(l)} W^{(l)} \\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0ea561f",
   "metadata": {},
   "source": [
    "### 损失函数 Loss Function\n",
    "- $ \\bar{Q}^{(v)} \\in R^{ n^{(v)} \\times n^{(v)} } $ 是从 $ \\bar{H}^{(v)} $ 构造的分布，是自由度为1的t分布；\n",
    "- $ KL(\\cdot||\\cdot) $ 是 Kullback-Leibler(KL)散度；\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "198c5cfb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{Q}_{i,j}^{(v)} = \\frac{\n",
    "    \\left(1 + || \\bar{h}_i^{(v)} - \\bar{h}_j^{(v)} ||^2\\right)^{-1}\n",
    "}{\n",
    "    \\sum_{k\\neq l} \\left(1 + || \\bar{h}_k^{(v)} - \\bar{h}_i^{(v)} ||^2\\right)^{-1}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c29f4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{t-SNE} = \\sum_{v=1}^V KL\\left( \\tilde{P}^{(v)} ||\\ \\bar{Q}^{(v)} \\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296a52b8",
   "metadata": {},
   "source": [
    "## 缺失视角特征补全模块 Feature Completion Module of Missing Views"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dbf1f55",
   "metadata": {},
   "source": [
    "### 视角专属解码器 View-specific Decoder\n",
    "\n",
    "- $ \\hat{X}^{(v)} \\in R^{ n^{(v)} \\times d^{(v)} } $ 是网络为每个视角重建的原始特征，其中包含对存在样本的重建和对不存在样本（缺失样本）的预测（补全）；\n",
    "- $ g^{(v)} $ 是解码器，$ \\Theta_D^{(v)} $ 是解码器的可学习参数；\n",
    "- $ H \\in R^{n \\times d} $ 是共识表示，$d$ 是共识表示的维度；\n",
    "- 解码器由全连接层和批归一化层组成；\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecbaa6a3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{X}^{(v)} = g^{(v)}\\left(H; \\Theta_D^{(v)}\\right) \\\\\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e035c97a",
   "metadata": {},
   "source": [
    "### 全连接层 Full-connected Layer\n",
    "\n",
    "- $ReLU(x) = \\max(0, x)$ ；\n",
    "- $ H^{(l)} $ 是网络第$l$层的输入，$H^{(0)} = X$ 是网络的输入；\n",
    "- $H^{(l+1)}$ 是网络第$l$层的输出，也是第$(l+1)$层的输入；\n",
    "- $ W^{(l)}, b^{(l)} $ 是网络第$l$层的可学习参数；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5926841",
   "metadata": {},
   "source": [
    "$$\n",
    "H^{(l+1)} = ReLU \\left( H^{(l)} W^{(l)} + b^{(l)} \\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f0f57af",
   "metadata": {},
   "source": [
    "### 损失函数 Loss Function\n",
    "\n",
    "- $ M^{(v)} \\in \\{0,1\\}^{n^{(v)} \\times n} $ 为缺失指示矩阵；\n",
    "- $ \\hat{X}^{(v)} \\in R^{ n^{(v)} \\times d^{(v)} } $ 是网络为每个视角重建的原始特征，其中包含对存在样本的重建和对不存在样本（缺失样本）的预测（补全）；\n",
    "- $ {X}^{(v)} \\in R^{ n \\times d^{(v)} } $ 为每个视角的所有样本（不存在的样本标记为NaN）；\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b8c6d83",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_{MSE} = \\sum_{v=1}^V \\frac{1}{n^{(v)}} \\left( M^{(v)}|| \\hat{X}^{(v)} - {X}^{(v)} ||^2 \\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26e8b902",
   "metadata": {},
   "source": [
    "### 总体损失函数 Overall Loss Function\n",
    "\n",
    "- $ \\mathcal{L}_{t-SNE} , \\mathcal{L}_{MSE} $ 分别是共识表示学习损失和特征补全损失；\n",
    "- $\\lambda > 0$ 是权衡上述两项损失函数的超参数；\n",
    "- 模型参数为：$\\Theta = \\{\\Theta^{(v)}_E,\\Theta^{(v)}_D\\}_{v=1}^{V} $；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f542ed2",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L} = \\mathcal{L}_{t-SNE} + \\lambda \\cdot \\mathcal{L}_{MSE}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3083b6e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L} = \\sum_{v=1}^V KL\\left( \\tilde{P}^{(v)} ||\\ \\bar{Q}^{(v)} \\right) + \\lambda \\cdot \\frac{1}{n^{(v)}} \\left( M^{(v)}|| \\hat{X}^{(v)} - {X}^{(v)} ||^2 \\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8781d9",
   "metadata": {},
   "source": [
    "## 实现细节 Implementation Details\n",
    "\n",
    "- 使用 Adam 优化器，学习率设置为0.0001；\n",
    "- 数据预处理：将每个特征归一化为0-1之间的实数；\n",
    "- 编码器的结构如下：\n",
    "  - 图卷积层-1\n",
    "  - 批归一化层-1\n",
    "  - 图卷积层-2\n",
    "  - 批归一化层-2\n",
    "- 解码器的结构如下：\n",
    "  - 批归一化层-3\n",
    "  - 全连接层-1\n",
    "  - 批归一化层-4\n",
    "  - 全连接层-2\n",
    "  - Sigmoid层\n",
    "- 超参数：\n",
    "  - $\\lambda$ 设置为0.1；\n",
    "  - 困惑度PPL设置为50;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
